{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3849, 0.2128, 0.3324,  ..., 0.6313, 0.0952, 0.8892],\n",
       "        [0.2804, 0.3638, 0.2067,  ..., 0.3791, 0.6019, 0.0328],\n",
       "        [0.3549, 0.0113, 0.6764,  ..., 0.0233, 0.1334, 0.6252],\n",
       "        ...,\n",
       "        [0.5554, 0.5693, 0.6836,  ..., 0.3386, 0.4260, 0.5500],\n",
       "        [0.6957, 0.6013, 0.7092,  ..., 0.3077, 0.5732, 0.1856],\n",
       "        [0.0157, 0.8280, 0.3015,  ..., 0.6044, 0.2103, 0.9776]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# make random matrix with dim 1000x162\n",
    "x = torch.rand(1000, 162).to(torch.float32).to('cuda').requires_grad_()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 µs ± 33.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "e = torch.mm(x,x.T.detach())\n",
    "e = e.sum()\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 µs ± 4.25 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "e = torch.mm(x,x.T.detach())\n",
    "e = e.sum()\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.mm(x,x.T)\n",
    "e = e.sum()\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1001.9821,  997.3248, 1029.8417,  ...,  992.7962,  996.6891,\n",
       "          985.8806],\n",
       "        [1001.9821,  997.3248, 1029.8417,  ...,  992.7962,  996.6891,\n",
       "          985.8806],\n",
       "        [1001.9821,  997.3248, 1029.8417,  ...,  992.7962,  996.6891,\n",
       "          985.8806],\n",
       "        ...,\n",
       "        [1001.9821,  997.3248, 1029.8417,  ...,  992.7962,  996.6891,\n",
       "          985.8806],\n",
       "        [1001.9821,  997.3248, 1029.8417,  ...,  992.7962,  996.6891,\n",
       "          985.8806],\n",
       "        [1001.9821,  997.3248, 1029.8417,  ...,  992.7962,  996.6891,\n",
       "          985.8806]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[500.9910, 498.6624, 514.9208,  ..., 496.3981, 498.3446, 492.9403],\n",
       "        [500.9910, 498.6624, 514.9208,  ..., 496.3981, 498.3446, 492.9403],\n",
       "        [500.9910, 498.6624, 514.9208,  ..., 496.3981, 498.3446, 492.9403],\n",
       "        ...,\n",
       "        [500.9910, 498.6624, 514.9208,  ..., 496.3981, 498.3446, 492.9403],\n",
       "        [500.9910, 498.6624, 514.9208,  ..., 496.3981, 498.3446, 492.9403],\n",
       "        [500.9910, 498.6624, 514.9208,  ..., 496.3981, 498.3446, 492.9403]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.mm(x,x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 µs ± 10.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "e = torch.mm(x,x.T)\n",
    "e = e.sum()\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangular matrix covering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "class GraphStructureLearner(torch.nn.Module):\n",
    "    def __init__(self, input_channels, num_heads, attention_threshold_epsilon, is_heterogeneous=False, metric_type='weighted_cosine'):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_threshold_epsilon = attention_threshold_epsilon\n",
    "        # weighted cosine\n",
    "        # (h, 1, dim)\n",
    "        if metric_type == 'weighted_cosine':\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.Tensor(num_heads, input_channels)).unsqueeze(1)\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.nn.init.xavier_uniform_(self.weight_tensor))\n",
    "            # initialize weights\n",
    "            \n",
    "            self.forward = self.forward_weighted_cosine\n",
    "            \n",
    "    \n",
    "    # non heterogeneous case\n",
    "    def forward_weighted_cosine(self, X, batch, has_converged)->int:\n",
    "        #  batch is the graph number for each node (the graph the node belongs to)\n",
    "        \n",
    "        X = X.unsqueeze(0) \n",
    "        \n",
    "        # hadamard product by broadcasting\n",
    "        # (h, 1, dim) * (1, n, dim) -> (h, n, dim)\n",
    "        X = torch.multiply(self.weight_tensor, X)\n",
    "        \n",
    "        # get the minibatch indices (star1, end1), (start2, end2), ... for each graph in the batch\n",
    "        changed = (batch.roll(-1) - batch).roll(1)\n",
    "        changed[0] += batch.max()\n",
    "        start = torch.cat([torch.tensor([0]).to(changed.device),torch.where(changed)[0], torch.tensor([batch.shape[-1]]).to(changed.device)])\n",
    "        end= start.roll(-1)\n",
    "        indices = torch.stack([start, end], dim=1)[:-1]\n",
    "\n",
    "        # compute attention for minibatch, save minibatch graphs together in one sparse tensor\n",
    "        edge_indices, edge_weights = [], []\n",
    "        \n",
    "        \n",
    "        Xnorm = F.normalize(X, p=2, dim=-1) # all values 0 precision if not converted to float64\n",
    "        \n",
    "        last_index = 0\n",
    "        not_converged = torch.argwhere(~has_converged).squeeze(1)\n",
    "        for i, (start,end) in enumerate(indices):\n",
    "            if i in not_converged:\n",
    "                E = Xnorm[:,start:end,:]\n",
    "                attention = torch.bmm(E, E.transpose(1,2))\n",
    "                attention = torch.mean(attention, dim=0)\n",
    "                # remove negative/small values under threshold epsilon\n",
    "                # attention = torch.where(attention > self.attention_threshold_epsilon, attention, torch.tensor(0.0))\n",
    "                mask = attention > self.attention_threshold_epsilon\n",
    "                # attention = attention[~torch.argwhere(mask)] = 0  # not needed, we only select the others for backprop anyways\n",
    "                \n",
    "                edge_index = torch.argwhere(mask).T #  indices of non-zero values\n",
    "                edge_weight = attention.masked_select(mask)\n",
    "                edge_index += last_index\n",
    "                edge_indices.append(edge_index)\n",
    "                edge_weights.append(edge_weight)\n",
    "                \n",
    "            last_index += (end - start)  # or simpler ...\n",
    "            \n",
    "\n",
    "        attention_edge_indices = torch.cat(edge_indices, dim=1)\n",
    "        attention_edge_weights = torch.cat(edge_weights, dim=0).unsqueeze(1)\n",
    "        \n",
    "        return attention_edge_indices, attention_edge_weights\n",
    "    \n",
    "    def forward(self, X, batch, has_converged)->int:\n",
    "        return self.forward_weighted_cosine(X, batch, has_converged)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(8000, 128).to(torch.float32).to('cuda')\n",
    "\n",
    "# make 12 batches so 0,0,0 .... 1,... 11,11,11\n",
    "batch = torch.arange(8000).to('cuda') // 666\n",
    "# false foe each batch\n",
    "has_converged = torch.zeros(12).to('cuda').bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0986, 0.3072, 0.7209,  ..., 0.6020, 0.9548, 0.5166],\n",
       "        [0.8276, 0.5639, 0.9150,  ..., 0.4976, 0.5375, 0.1376],\n",
       "        [0.0347, 0.9868, 0.3028,  ..., 0.4488, 0.0330, 0.6578],\n",
       "        ...,\n",
       "        [0.2962, 0.8004, 0.6789,  ..., 0.8754, 0.9087, 0.9244],\n",
       "        [0.1825, 0.0325, 0.8129,  ..., 0.8835, 0.2323, 0.0985],\n",
       "        [0.4844, 0.7780, 0.6184,  ..., 0.9413, 0.7000, 0.5545]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_learner = GraphStructureLearner(128, 4, 0.1).cuda()\n",
    "x1 = x.clone()\n",
    "x1.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2 ms ± 93 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "torch.cuda.synchronize()\n",
    "_,e = structure_learner(x1, batch, has_converged)\n",
    "e = e.sum()\n",
    "e.backward()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import time \n",
    "\n",
    "class GraphStructureLearnerOptimtime(torch.nn.Module):\n",
    "    def __init__(self, input_channels, num_heads, attention_threshold_epsilon, is_heterogeneous=False, metric_type='weighted_cosine'):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_threshold_epsilon = attention_threshold_epsilon\n",
    "        # weighted cosine\n",
    "        # (h, 1, dim)\n",
    "        if metric_type == 'weighted_cosine':\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.Tensor(num_heads, input_channels)).unsqueeze(1)\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.nn.init.xavier_uniform_(self.weight_tensor))\n",
    "            # initialize weights\n",
    "            \n",
    "            self.forward = self.forward_weighted_cosine\n",
    "            \n",
    "    \n",
    "    # non heterogeneous case\n",
    "    def forward_weighted_cosine(self, X, batch, has_converged)->int:\n",
    "        #  batch is the graph number for each node (the graph the node belongs to)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        time1 = time.time()\n",
    "        X = X.unsqueeze(0) \n",
    "        \n",
    "        # hadamard product by broadcasting\n",
    "        # (h, 1, dim) * (1, n, dim) -> (h, n, dim)\n",
    "        X = torch.multiply(self.weight_tensor, X)\n",
    "        \n",
    "        # get the minibatch indices (star1, end1), (start2, end2), ... for each graph in the batch\n",
    "        changed = (batch.roll(-1) - batch).roll(1)\n",
    "        changed[0] += batch.max()\n",
    "        start = torch.cat([torch.tensor([0]).to(changed.device),torch.where(changed)[0], torch.tensor([batch.shape[-1]]).to(changed.device)])\n",
    "        end= start.roll(-1)\n",
    "        indices = torch.stack([start, end], dim=1)[:-1]\n",
    "        torch.cuda.synchronize()\n",
    "        time2 = time.time()\n",
    "        # compute attention for minibatch, save minibatch graphs together in one sparse tensor\n",
    "        edge_indices, edge_weights = [], []\n",
    "        \n",
    "        \n",
    "        Xnorm = F.normalize(X, p=2, dim=-1) # all values 0 precision if not converted to float64\n",
    "        torch.cuda.synchronize()\n",
    "        time3 = time.time()\n",
    "        # Xnorm_detached = Xnorm.detach()\n",
    "        last_index = 0\n",
    "        not_converged = torch.argwhere(~has_converged).squeeze(1)\n",
    "        for i, (start,end) in enumerate(indices):\n",
    "            if i in not_converged:\n",
    "                E = Xnorm[:,start:end,:]\n",
    "                # Et = Xnorm_detached[:,start:end,:]\n",
    "                attention = torch.bmm(E, E.transpose(1,2).detach())\n",
    "                attention = torch.mean(attention, dim=0)\n",
    "                # remove negative/small values under threshold epsilon\n",
    "                # attention = torch.where(attention > self.attention_threshold_epsilon, attention, torch.tensor(0.0))\n",
    "                mask = attention > self.attention_threshold_epsilon\n",
    "                # attention = attention[~torch.argwhere(mask)] = 0  # not needed, we only select the others for backprop anyways\n",
    "                \n",
    "                edge_index = torch.argwhere(mask).T #  indices of non-zero values\n",
    "                edge_weight = attention.masked_select(mask)\n",
    "                edge_index += last_index\n",
    "                edge_indices.append(edge_index)\n",
    "                edge_weights.append(edge_weight)\n",
    "                \n",
    "            last_index += (end - start)  # or simpler ...\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        timea = time.time()\n",
    "        for i, (start,end) in enumerate(indices):\n",
    "            if i in not_converged:\n",
    "                E = Xnorm[:,start:end,:]\n",
    "                # Et = Xnorm_detached[:,start:end,:]\n",
    "                attention = torch.bmm(E, E.transpose(1,2).detach())\n",
    "        torch.cuda.synchronize()\n",
    "        timeb = time.time()\n",
    "        weights1 = []\n",
    "        weights2 = []\n",
    "        for i, (start,end) in enumerate(indices):\n",
    "            if i in not_converged:\n",
    "                mask = attention > self.attention_threshold_epsilon\n",
    "                edge_index = torch.argwhere(mask).T #  indices of non-zero values\n",
    "                edge_weight = attention.masked_select(mask)\n",
    "                # edge_index += last_index\n",
    "                # weights1.append(edge_index)\n",
    "                # weights2.append(edge_weight)\n",
    "        torch.cuda.synchronize()\n",
    "        timec = time.time()\n",
    "            \n",
    "        torch.cuda.synchronize()\n",
    "        time4 = time.time()\n",
    "        attention_edge_indices = torch.cat(edge_indices, dim=1)\n",
    "        attention_edge_weights = torch.cat(edge_weights, dim=0).unsqueeze(1)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        time5 = time.time()\n",
    "        \n",
    "        return attention_edge_indices, attention_edge_weights, time2-time1, time3-time2, time4-time3, time5-time4, timeb-timea, timec-timeb\n",
    "    \n",
    "    def forward(self, X, batch, has_converged)->int:\n",
    "        return self.forward_weighted_cosine(X, batch, has_converged)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import time \n",
    "\n",
    "class GraphStructureLearnerOptim(torch.nn.Module):\n",
    "    def __init__(self, input_channels, num_heads, attention_threshold_epsilon, is_heterogeneous=False, metric_type='weighted_cosine'):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_threshold_epsilon = attention_threshold_epsilon\n",
    "        # weighted cosine\n",
    "        # (h, 1, dim)\n",
    "        if metric_type == 'weighted_cosine':\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.Tensor(num_heads, input_channels)).unsqueeze(1)\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.nn.init.xavier_uniform_(self.weight_tensor))\n",
    "            # initialize weights\n",
    "            \n",
    "            self.forward = self.forward_weighted_cosine\n",
    "            \n",
    "    \n",
    "    # non heterogeneous case\n",
    "    def forward_weighted_cosine(self, X, batch, has_converged)->int:\n",
    "        #  batch is the graph number for each node (the graph the node belongs to)\n",
    "        \n",
    "        X = X.unsqueeze(0) \n",
    "        \n",
    "        # hadamard product by broadcasting\n",
    "        # (h, 1, dim) * (1, n, dim) -> (h, n, dim)\n",
    "        X = torch.multiply(self.weight_tensor, X)\n",
    "        \n",
    "        # get the minibatch indices (star1, end1), (start2, end2), ... for each graph in the batch\n",
    "        changed = (batch.roll(-1) - batch).roll(1)\n",
    "        changed[0] += batch.max()\n",
    "        start = torch.cat([torch.tensor([0]).to(changed.device),torch.where(changed)[0], torch.tensor([batch.shape[-1]]).to(changed.device)])\n",
    "        end= start.roll(-1)\n",
    "        indices = torch.stack([start, end], dim=1)[:-1]\n",
    "        # compute attention for minibatch, save minibatch graphs together in one sparse tensor\n",
    "        edge_indices, edge_weights = [], []\n",
    "        \n",
    "        \n",
    "        Xnorm = F.normalize(X, p=2, dim=-1) # all values 0 precision if not converted to float64\n",
    "        # Xnorm_detached = Xnorm.detach()\n",
    "        last_index = 0\n",
    "        not_converged = torch.argwhere(~has_converged).squeeze(1)\n",
    "        for i, (start,end) in enumerate(indices):\n",
    "            if i in not_converged:\n",
    "                E = Xnorm[:,start:end,:]\n",
    "                # Et = Xnorm_detached[:,start:end,:]\n",
    "                attention = torch.bmm(E, E.transpose(1,2).detach())\n",
    "                attention = torch.mean(attention, dim=0)\n",
    "                # remove negative/small values under threshold epsilon\n",
    "                # attention = torch.where(attention > self.attention_threshold_epsilon, attention, torch.tensor(0.0))\n",
    "                mask = attention > self.attention_threshold_epsilon\n",
    "                # attention = attention[~torch.argwhere(mask)] = 0  # not needed, we only select the others for backprop anyways\n",
    "                \n",
    "                edge_index = torch.argwhere(mask).T #  indices of non-zero values\n",
    "                edge_weight = attention.masked_select(mask)\n",
    "                edge_index += last_index\n",
    "                edge_indices.append(edge_index)\n",
    "                edge_weights.append(edge_weight)\n",
    "                \n",
    "            last_index += (end - start)  # or simpler ...\n",
    "            \n",
    "        attention_edge_indices = torch.cat(edge_indices, dim=1)\n",
    "        attention_edge_weights = torch.cat(edge_weights, dim=0).unsqueeze(1)\n",
    "        \n",
    "        return attention_edge_indices, attention_edge_weights\n",
    "    \n",
    "    def forward(self, X, batch, has_converged)->int:\n",
    "        return self.forward_weighted_cosine(X, batch, has_converged)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import time \n",
    "\n",
    "class GraphStructureLearnerOptim2(torch.nn.Module):\n",
    "    def __init__(self, input_channels, num_heads, attention_threshold_epsilon, is_heterogeneous=False, metric_type='weighted_cosine'):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_threshold_epsilon = attention_threshold_epsilon\n",
    "        # weighted cosine\n",
    "        # (h, 1, dim)\n",
    "        if metric_type == 'weighted_cosine':\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.Tensor(num_heads, input_channels)).unsqueeze(1)\n",
    "            self.weight_tensor = torch.nn.Parameter(torch.nn.init.xavier_uniform_(self.weight_tensor))\n",
    "            # initialize weights\n",
    "            \n",
    "            self.forward = self.forward_weighted_cosine\n",
    "            \n",
    "    \n",
    "    # non heterogeneous case\n",
    "    def forward_weighted_cosine(self, X, batch, has_converged)->int:\n",
    "        #  batch is the graph number for each node (the graph the node belongs to)\n",
    "        \n",
    "        X = X.unsqueeze(0) \n",
    "        \n",
    "        # hadamard product by broadcasting\n",
    "        # (h, 1, dim) * (1, n, dim) -> (h, n, dim)\n",
    "        X = torch.multiply(self.weight_tensor, X)\n",
    "        \n",
    "        # get the minibatch indices (star1, end1), (start2, end2), ... for each graph in the batch\n",
    "        Xnorm = F.normalize(X, p=2, dim=-1) # all values 0 precision if not converted to float64\n",
    "        attention = torch.bmm(Xnorm, Xnorm.transpose(1,2).detach())\n",
    "        attention = torch.mean(attention, dim=0)\n",
    "        mask = attention > self.attention_threshold_epsilon\n",
    "        attention_edge_indices = torch.argwhere(mask).T #  indices of non-zero values\n",
    "        attention_edge_weights = attention.masked_select(mask)\n",
    "        \n",
    "        return attention_edge_indices, attention_edge_weights\n",
    "    \n",
    "    def forward(self, X, batch, has_converged)->int:\n",
    "        return self.forward_weighted_cosine(X, batch, has_converged)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0986, 0.3072, 0.7209,  ..., 0.6020, 0.9548, 0.5166],\n",
       "        [0.8276, 0.5639, 0.9150,  ..., 0.4976, 0.5375, 0.1376],\n",
       "        [0.0347, 0.9868, 0.3028,  ..., 0.4488, 0.0330, 0.6578],\n",
       "        ...,\n",
       "        [0.2962, 0.8004, 0.6789,  ..., 0.8754, 0.9087, 0.9244],\n",
       "        [0.1825, 0.0325, 0.8129,  ..., 0.8835, 0.2323, 0.0985],\n",
       "        [0.4844, 0.7780, 0.6184,  ..., 0.9413, 0.7000, 0.5545]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_learner2 = GraphStructureLearnerOptim(128, 4, 0.1).cuda()\n",
    "x2 = x.clone()\n",
    "x2.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4 ms ± 55.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%timeit\n",
    "torch.cuda.synchronize()\n",
    "indices,e = structure_learner2(x2, batch, has_converged)\n",
    "e = e.sum()\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0986, 0.3072, 0.7209,  ..., 0.6020, 0.9548, 0.5166],\n",
       "        [0.8276, 0.5639, 0.9150,  ..., 0.4976, 0.5375, 0.1376],\n",
       "        [0.0347, 0.9868, 0.3028,  ..., 0.4488, 0.0330, 0.6578],\n",
       "        ...,\n",
       "        [0.2962, 0.8004, 0.6789,  ..., 0.8754, 0.9087, 0.9244],\n",
       "        [0.1825, 0.0325, 0.8129,  ..., 0.8835, 0.2323, 0.0985],\n",
       "        [0.4844, 0.7780, 0.6184,  ..., 0.9413, 0.7000, 0.5545]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_learner3 = GraphStructureLearnerOptim2(128, 4, 0.1).cuda()\n",
    "x3 = x.clone()\n",
    "x3.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 ms ± 576 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%timeit\n",
    "torch.cuda.synchronize()\n",
    "for i in range(16):\n",
    "    indices,e = structure_learner3(x3[i*(8000//16):(i+1)*(8000//16)], batch, has_converged)\n",
    "    e.sum().backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1141.2169, -172.5217,  442.3118,  ..., -308.8889, 1508.8729,\n",
       "           36.1408],\n",
       "        [-187.2372,  197.1149,  408.1441,  ...,  492.9110, 1770.6268,\n",
       "          281.8169],\n",
       "        [-414.2870,  676.9843, -158.0955,  ...,  -75.8605,  895.7821,\n",
       "         -110.5858],\n",
       "        ...,\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 398.6671, -235.8796, 2067.4553,  ..., -547.0215, 1166.7192,\n",
       "           70.0552],\n",
       "        [ -40.9576,  283.5767, 1944.9091,  ...,  847.5580, 1355.4150,\n",
       "          609.4676],\n",
       "        [-220.3365,  978.3788, -837.9225,  ..., -147.2248,  681.3812,\n",
       "         -265.3523],\n",
       "        ...,\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m      5\u001b[0m x2\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m indices,e, time1, time2, time3, time4, timea, timeb\u001b[38;5;241m=\u001b[39m \u001b[43mstructure_learner2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_converged\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m times1\u001b[38;5;241m.\u001b[39mappend(time1)\n\u001b[1;32m      9\u001b[0m times2\u001b[38;5;241m.\u001b[39mappend(time2)\n",
      "File \u001b[0;32m/opt/conda/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[167], line 82\u001b[0m, in \u001b[0;36mGraphStructureLearnerOptimtime.forward_weighted_cosine\u001b[0;34m(self, X, batch, has_converged)\u001b[0m\n\u001b[1;32m     80\u001b[0m weights2 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (start,end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indices):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnot_converged\u001b[49m:\n\u001b[1;32m     83\u001b[0m         mask \u001b[38;5;241m=\u001b[39m attention \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_threshold_epsilon\n\u001b[1;32m     84\u001b[0m         edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margwhere(mask)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;66;03m#  indices of non-zero values\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pyg/lib/python3.11/site-packages/torch/_tensor.py:1091\u001b[0m, in \u001b[0;36mTensor.__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__contains__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, element)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1088\u001b[0m     element, (torch\u001b[38;5;241m.\u001b[39mTensor, Number, torch\u001b[38;5;241m.\u001b[39mSymInt, torch\u001b[38;5;241m.\u001b[39mSymFloat, torch\u001b[38;5;241m.\u001b[39mSymBool)\n\u001b[1;32m   1089\u001b[0m ):\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[0;32m-> 1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1095\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "times1, times2,times3,times4,times5,timesa,timesb = [],[],[],[],[],[],[]\n",
    "for i in range(1000):\n",
    "    structure_learner2 = GraphStructureLearnerOptimtime(128, 4, 0.1).cuda()\n",
    "    x2 = x.clone()\n",
    "    x2.requires_grad_(True)\n",
    "\n",
    "    indices,e, time1, time2, time3, time4, timea, timeb= structure_learner2(x2, batch, has_converged)\n",
    "    times1.append(time1)\n",
    "    times2.append(time2)\n",
    "    times3.append(time3)\n",
    "    times4.append(time4)\n",
    "    timesa.append(timea)\n",
    "    timesb.append(timeb)\n",
    "    \n",
    "    e = e.sum()\n",
    "    torch.cuda.synchronize()\n",
    "    time5 = time.time()\n",
    "    e.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    time5 = time.time() - time5\n",
    "    times5.append(time5)\n",
    "\n",
    "print(sum(times1)/len(times1), sum(times2)/len(times2), sum(times3)/len(times3), sum(times4)/len(times4), sum(times5)/len(times5), sum(timesa)/len(timesa), sum(timesb)/len(timesb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0022389500141143798 0.01698826265335083\n",
    "0.002236340284347534 0.000594428300857544\n",
    "\n",
    "0.0003767564296722412 0.00025538945198059083 0.014358247756958008 0.0010652749538421632 0.011078863620758057 0.002239511966705322 0.005343229055404663\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3830012367.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[153], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    0.0003784432411193848 0.00025416707992553713 0.007009508609771728 0.0010624141693115234 0.011068058490753175\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "0.0003784432411193848 0.00025416707992553713 0.007009508609771728 0.0010624141693115234 0.011068058490753175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1505, -0.7693,  0.9857,  ..., -0.1066,  0.4547, -0.6688],\n",
       "        [ 0.3987,  0.9820,  0.3226,  ...,  0.3678, -0.7398, -0.3567],\n",
       "        [ 0.5150,  0.9157,  0.0548,  ...,  0.1412,  0.7922,  0.7795],\n",
       "        ...,\n",
       "        [ 0.9898, -0.9740, -0.5937,  ..., -0.4817, -0.0546,  0.2182],\n",
       "        [-0.4179, -0.8088, -0.6399,  ..., -0.0083,  0.6907, -0.8968],\n",
       "        [ 0.0456,  0.9002, -0.1455,  ...,  0.6903,  0.3910, -0.1203]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make random float tensor 100x100 with weights from -1 to 1 \n",
    "xa = torch.rand(100, 100).to(torch.float32).to('cuda') * 2 - 1\n",
    "xa.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9222,  0.1429,  0.3722,  ...,  0.0598, -0.6948,  0.3111],\n",
       "        [ 0.1324, -0.4627,  0.9854,  ..., -0.1995,  0.1942,  0.0766],\n",
       "        [ 0.4638, -0.3174, -0.8356,  ..., -0.0672,  0.0100, -0.2991],\n",
       "        ...,\n",
       "        [ 0.2514,  0.8340, -0.6442,  ..., -0.9268,  0.3634, -0.3279],\n",
       "        [ 0.7734,  0.5188,  0.6181,  ...,  0.2777, -0.4139, -0.0737],\n",
       "        [ 0.3979, -0.5447, -0.4936,  ...,  0.1326, -0.1847,  0.2321]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xa = torch.rand(100, 100).to(torch.float32).to('cuda') * 2 - 1\n",
    "xa.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = xa > 0.1\n",
    "edge_index = torch.argwhere(mask).T #  indices of non-zero values\n",
    "edge_weight = xa.masked_select(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 µs ± 961 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.cuda.synchronize()\n",
    "mask = xa > 0.1\n",
    "edge_index = torch.nonzero(mask).T\n",
    "edge_weight = xa[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 99, 99, 99],\n",
       "        [ 0,  1,  2,  ..., 96, 97, 99]], device='cuda:0')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 99, 99, 99],\n",
       "        [ 0,  1,  2,  ..., 96, 97, 99]], device='cuda:0')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9222, 0.1429, 0.3722,  ..., 0.4655, 0.1326, 0.2321], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9222, 0.1429, 0.3722,  ..., 0.4655, 0.1326, 0.2321], device='cuda:0',\n",
       "       grad_fn=<MaskedSelectBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
